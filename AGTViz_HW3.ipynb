{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework â„–3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Student: *Smirnov Aleksandr*</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Those how are making projects on artilces: half of you need to choose co-authorship graph!, others - citation (but consider citation graph as undirected for simplicity)\n",
    "2. Use weighted graph so that it would give you ability to calculate embeddings in more appropriate way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initiallize your classification set as follows:\n",
    "    * Determine training and testing intervals on your time domain (for example, take a period $2000$-$2014$ as training period and $2015$-$2018$ as testing period)\n",
    "    * Pick pairs of nodes that **have appeared during training interval** but **had no links** during it\n",
    "    * These pairs form **positive** or **negative** examples depending on whether they have formed coauthorships **during the testing interval**\n",
    "    * You have arrived to binary classification problem.\n",
    "2. Construct feature space:\n",
    "    * Use at least 2 features based on neighborhood \n",
    "    * Use at least 2 fetures based on shortest path\n",
    "    * Use embedding representation of nodes' pairs (for example, node2vec)\n",
    "    * Use idea of time series features (with time lag)\n",
    "    * Use idea of change-point detection\n",
    "3. Choose at least $3$ classification algorithms and compare them in terms of Accuracy, Precision, Recall, F-Score (for positive class) and Mean Squared Error. Use k-fold cross-validation and average your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's upload our data\n",
    "\n",
    "As far, as I've understood, in order to use the idea of time series, we have to devide our initial data by some lag, for this case, let it be 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder\n",
    "from networkx.classes.function import density\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Articles = pandas.read_excel('articles.xls')\n",
    "Articles = Articles.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authors = []\n",
    "test_authors = []\n",
    "for i in range(len(Articles)):\n",
    "    try:\n",
    "        if Articles['date'][i].year <= 2015:\n",
    "            train_authors.append(Articles['Author'][i])\n",
    "        else:\n",
    "            test_authors.append(Articles['Author'][i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2016, 2018, 2014, 2019, 2010, 2013, 2015, 2017, 2011, 2012])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2010, 999),\n",
       " (2011, 1500),\n",
       " (2012, 1000),\n",
       " (2013, 1499),\n",
       " (2014, 1999),\n",
       " (2015, 1000),\n",
       " (2016, 2748),\n",
       " (2017, 2499),\n",
       " (2018, 1449),\n",
       " (2019, 1675)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(years.keys(), map(lambda x: len(years[x]), years))), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as our data has been devided by years, we can take 3 years in a row and make training data out of them.\n",
    "\n",
    "We will calculate some features for first two years, and get our target values from the third year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some helping functions like *del_all_extras* in order to delete all nodes wich are not in a target domain, sure, we will compute all of our metrics like shortest path on a default graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_extra_nodes(first_G, second_G):\n",
    "    for node in first_G.copy():\n",
    "        if node not in second_G:\n",
    "            first_G.remove_node(node)\n",
    "            \n",
    "\n",
    "def del_all_extras(G_1, G_2, G_3):\n",
    "    del_extra_nodes(G_1, G_2)\n",
    "    del_extra_nodes(G_1, G_3)\n",
    "    del_extra_nodes(G_2, G_1)\n",
    "    del_extra_nodes(G_2, G_3)\n",
    "    del_extra_nodes(G_3, G_1)\n",
    "    del_extra_nodes(G_3, G_2)\n",
    "            \n",
    "        \n",
    "def get_not_connected(G):\n",
    "    not_connected = []\n",
    "    for node_1 in G.nodes():\n",
    "        for node_2 in G.nodes():\n",
    "            if node_1 < node_2 and not G.has_edge(node_1, node_2):\n",
    "                not_connected.append((node_1, node_2))\n",
    "    return not_connected\n",
    "\n",
    "\n",
    "def edge_tuple(node_1, node_2):\n",
    "    return (min(node_1, node_2), max(node_1, node_2))\n",
    "    \n",
    "\n",
    "def collect_edges(authors):\n",
    "    res={}\n",
    "    for i in authors:\n",
    "        try:\n",
    "            aus=i.split(';')\n",
    "            auids=[l.split(':')[1] for l in aus]\n",
    "            for j in auids:\n",
    "                c=Counter([k for k in auids if k!=j])\n",
    "                if j in res:\n",
    "                    res[j]+=c\n",
    "                else:\n",
    "                    res[j]=c\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "    edges=[]\n",
    "    for k, v in res.items():\n",
    "        for j, w in v.items():\n",
    "            edges.append((k, j, w))\n",
    "            \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here lay all functions for feature computation\n",
    "\n",
    "For features based on neighborhood we will use: jaccard coefficient and number of common neighbors between two nodes\n",
    "For features based on shortest path we will use: length of the shortest path and page range between two nodes\n",
    "Also we will compute node2vec embedding representation of nodes' pairs\n",
    "And as for change-point detection we will use graph density, closeness_centrality and betweenness_centrality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard(G_1, G_2, not_connected, X):\n",
    "    preds_1 = nx.jaccard_coefficient(G_1, not_connected)\n",
    "    preds_2 = nx.jaccard_coefficient(G_2, not_connected)\n",
    "    \n",
    "    for from_v, to_v, coeff in preds_1:\n",
    "        X[edge_tuple(from_v, to_v)].append(coeff)\n",
    "    \n",
    "    for from_v, to_v, coeff in preds_2:\n",
    "        X[edge_tuple(from_v, to_v)].append(coeff)\n",
    "        \n",
    "\n",
    "def compute_common_neighbors(G_1, G_2, not_connected, X):\n",
    "    for (from_v, to_v) in not_connected:\n",
    "        X[edge_tuple(from_v, to_v)].append(len(list(nx.common_neighbors(G_1, from_v, to_v))))\n",
    "        X[edge_tuple(from_v, to_v)].append(len(list(nx.common_neighbors(G_2, from_v, to_v))))\n",
    "        \n",
    "        \n",
    "def compute_shortest_paths(G_1, G_2, not_connected, X):\n",
    "    for (from_v, to_v) in not_connected:\n",
    "        if nx.has_path(G_1, from_v, to_v):\n",
    "            X[edge_tuple(from_v, to_v)].append(nx.shortest_path_length(G_1, from_v, to_v))\n",
    "        else: \n",
    "            X[edge_tuple(from_v, to_v)].append(10**5)\n",
    "            \n",
    "        if nx.has_path(G_2, from_v, to_v):\n",
    "            X[edge_tuple(from_v, to_v)].append(nx.shortest_path_length(G_2, from_v, to_v))\n",
    "        else: \n",
    "            X[edge_tuple(from_v, to_v)].append(10**5)    \n",
    "            \n",
    "def compute_pagerank(G_1, G_2, not_connected, X):\n",
    "    pr_1 = nx.pagerank(G_1)\n",
    "    pr_2 = nx.pagerank(G_2)\n",
    "    \n",
    "    for (from_v, to_v) in not_connected:\n",
    "        X[edge_tuple(from_v, to_v)].append(np.mean((pr_1[from_v], pr_1[to_v])))\n",
    "        X[edge_tuple(from_v, to_v)].append(np.mean((pr_2[from_v], pr_2[to_v])))\n",
    "        \n",
    "        \n",
    "def compute_node2vec(G_1, G_2, not_connected, X):\n",
    "    # Precompute probabilities and generate walks\n",
    "    node2vec_1 = Node2Vec(G_1, dimensions=64, walk_length=30, num_walks=200, workers=4, quiet=True)\n",
    "    model_1 = node2vec_1.fit()\n",
    "    edges_embs_1 = HadamardEmbedder(keyed_vectors=model_1.wv)\n",
    "    \n",
    "    node2vec_2 = Node2Vec(G_2, dimensions=64, walk_length=30, num_walks=200, workers=4, quiet=True)\n",
    "    model_2 = node2vec_2.fit()\n",
    "    edges_embs_2 = HadamardEmbedder(keyed_vectors=model_2.wv)\n",
    "    \n",
    "    for (from_v, to_v) in not_connected:\n",
    "        for emb in edges_embs_1[(from_v, to_v)]:\n",
    "            X[edge_tuple(from_v, to_v)].append(emb)\n",
    "        \n",
    "        for emb in edges_embs_2[(from_v, to_v)]:\n",
    "            X[edge_tuple(from_v, to_v)].append(emb)\n",
    "            \n",
    "            \n",
    "def compute_density(G_1, G_2, X):\n",
    "    d_1 = density(G_1)\n",
    "    d_2 = density(G_2)\n",
    "    \n",
    "    for edge in X:\n",
    "        X[edge].append(d_1)\n",
    "        X[edge].append(d_2)\n",
    "        \n",
    "\n",
    "def compute_closeness_centrality(G_1, G_2, X):\n",
    "    CC_1 = np.mean([i for _, i in nx.closeness_centrality(G_1).items()])\n",
    "    CC_2 = np.mean([i for _, i in nx.closeness_centrality(G_2).items()])\n",
    "    for edge in X:\n",
    "        X[edge].append(CC_1)\n",
    "        X[edge].append(CC_2)\n",
    "        \n",
    "        \n",
    "def compute_betweenness_centrality(G_1, G_2, X):\n",
    "    BC_1 = np.mean([i for _, i in nx.betweenness_centrality(G_1).items()])\n",
    "    BC_2 = np.mean([i for _, i in nx.betweenness_centrality(G_2).items()])\n",
    "    for edge in X:\n",
    "        X[edge].append(BC_1)\n",
    "        X[edge].append(BC_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes needed years as an input and collects all features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_and_targets(prev_y, cur_y, next_y):\n",
    "    prev_G = nx.Graph()\n",
    "    prev_G_full = nx.Graph()\n",
    "    \n",
    "    cur_G = nx.Graph()\n",
    "    cur_G_full = nx.Graph()\n",
    "    \n",
    "    next_G = nx.Graph()\n",
    "    \n",
    "    prev_G.add_weighted_edges_from(collect_edges(prev_y))\n",
    "    prev_G_full.add_weighted_edges_from(collect_edges(prev_y))\n",
    "    \n",
    "    cur_G.add_weighted_edges_from(collect_edges(cur_y))\n",
    "    cur_G_full.add_weighted_edges_from(collect_edges(cur_y))\n",
    "    \n",
    "    next_G.add_weighted_edges_from(collect_edges(next_y))\n",
    "    \n",
    "    del_all_extras(prev_G, cur_G, next_G)\n",
    "    \n",
    "    not_connected_1 = get_not_connected(prev_G)\n",
    "    not_connected_2 = get_not_connected(cur_G)\n",
    "    \n",
    "    similar_not_connected = [edge for edge in not_connected_1 if edge in not_connected_2]\n",
    "    \n",
    "    X = {edge: [] for edge in similar_not_connected}\n",
    "    Y = {edge: next_G.has_edge(*edge) for edge in similar_not_connected}\n",
    "    \n",
    "    \n",
    "    # features based on neighborhood\n",
    "    compute_jaccard(prev_G_full, cur_G_full, similar_not_connected, X)\n",
    "    compute_common_neighbors(prev_G_full, cur_G_full, similar_not_connected, X)\n",
    "    \n",
    "    \n",
    "    # features based on shortest path\n",
    "    compute_shortest_paths(prev_G_full, cur_G_full, similar_not_connected, X)\n",
    "    compute_pagerank(prev_G_full, cur_G_full, similar_not_connected, X)\n",
    "    \n",
    "    \n",
    "    # node2vec\n",
    "    compute_node2vec(prev_G, cur_G, similar_not_connected, X)\n",
    "    \n",
    "    \n",
    "    # graph density\n",
    "    compute_density(prev_G, cur_G, X)\n",
    "    \n",
    "    \n",
    "    # centralities\n",
    "    compute_closeness_centrality(prev_G, cur_G, X)\n",
    "    compute_betweenness_centrality(prev_G, cur_G, X)\n",
    "    # print(X)\n",
    "    \n",
    "#    for edge in similar_not_connected:\n",
    "#        if next_G.has_edge(*edge):\n",
    "#            print(edge)\n",
    "\n",
    "#    print(prev_G.nodes() == cur_G.nodes(), cur_G.nodes() == next_G.nodes())\n",
    "#    print(prev_G.edges() == cur_G.edges(), cur_G.edges() == next_G.edges())    \n",
    "    \n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's process our uploaded data and collect X and Y for all time series (unfortunatly, years below 2012 got no suitable edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_X_Y():\n",
    "    X = dict()\n",
    "    Y = dict()\n",
    "    for year in years.keys():        \n",
    "        if year < 2018 and year > 2012:\n",
    "            print('Collecting year: ', year)\n",
    "            X[year], Y[year] = compute_features_and_targets(years[year],\n",
    "                                                            years[year+1],\n",
    "                                                            years[year+2])\n",
    "    return X, Y         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting year:  2016\n",
      "Collecting year:  2014\n",
      "Collecting year:  2013\n",
      "Collecting year:  2015\n",
      "Collecting year:  2017\n"
     ]
    }
   ],
   "source": [
    "All_X, All_Y = collect_all_X_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = [2016]\n",
    "test_years = [2013, 2014, 2015, 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_X_Y_by_year(selected_years):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for year in selected_years:\n",
    "        part_X = All_X[year]\n",
    "        part_Y = All_Y[year]\n",
    "        \n",
    "        keys = part_X.keys()\n",
    "        \n",
    "        for key in keys:\n",
    "            X.append(part_X[key])\n",
    "            Y.append(part_Y[key])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = collect_X_Y_by_year(train_years)\n",
    "X_test, Y_test = collect_X_Y_by_year(test_years)\n",
    "\n",
    "Y_train = list(map(float, Y_train))\n",
    "Y_test = list(map(float, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493.0"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19414"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1480"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we've chosen only one time period for the training set, leaving the rest time periods for the test, testing set is still very small, with a little number of appearde edges, well, that's all what we've got, now we shall proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with *check scores* function, which will evaluate all the needed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scores(Y_true, Y_pred):\n",
    "    print('Accuracy score: ', accuracy_score(Y_true, Y_pred))\n",
    "    print('Precision score: ', precision_score(Y_true, Y_pred))\n",
    "    print('Recall score: ', recall_score(Y_true, Y_pred))\n",
    "    print('F-score: ', f1_score(Y_true, Y_pred))\n",
    "    print('MSE: ', MSE(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've got bianry classification problem, I've decided to use Random Forest, Logistic Regression, SVM and Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9675675675675676\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F-score:  0.0\n",
      "MSE:  0.032432432432432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier(n_estimators=500)\n",
    "RF_clf.fit(X_train, Y_train)\n",
    "check_scores(Y_test, RF_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  1.0\n",
      "Precision score:  1.0\n",
      "Recall score:  1.0\n",
      "F-score:  1.0\n",
      "MSE:  0.0\n"
     ]
    }
   ],
   "source": [
    "check_scores(Y_train, RF_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9675675675675676\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F-score:  0.0\n",
      "MSE:  0.032432432432432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC(gamma='auto')\n",
    "svm_clf.fit(X_train, Y_train)\n",
    "check_scores(Y_test, svm_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9771814154733698\n",
      "Precision score:  0.7272727272727273\n",
      "Recall score:  0.16227180527383367\n",
      "F-score:  0.26533996683250416\n",
      "MSE:  0.022818584526630267\n"
     ]
    }
   ],
   "source": [
    "check_scores(Y_train, svm_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9675675675675676\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F-score:  0.0\n",
      "MSE:  0.032432432432432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "LR_clf = LogisticRegression(solver='liblinear').fit(X_train, Y_train)\n",
    "\n",
    "check_scores(Y_test, LR_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9708457813948697\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F-score:  0.0\n",
      "MSE:  0.02915421860513032\n"
     ]
    }
   ],
   "source": [
    "check_scores(Y_train, LR_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9675675675675676\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F-score:  0.0\n",
      "MSE:  0.032432432432432434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alex/Workspace/4th_grade/Graphs_2/env/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Ada_clf = AdaBoostClassifier()\n",
    "Ada_clf.fit(X_train, Y_train)\n",
    "check_scores(Y_test, Ada_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9770268878129185\n",
      "Precision score:  0.5951417004048583\n",
      "Recall score:  0.29817444219066935\n",
      "F-score:  0.39729729729729724\n",
      "MSE:  0.022973112187081486\n"
     ]
    }
   ],
   "source": [
    "check_scores(Y_train, Ada_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well I'm kind of disappointed, because of low precision, recall and F scores\n",
    "\n",
    "It might be because of small number of appeared edges int the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(142, 50)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout = self.dout(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "        h2 = self.prelu(a2)\n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    \n",
    "net = Net()\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, torch.Tensor(X_train).size(0), batch_size):\n",
    "        x_batch = torch.Tensor(X_train)[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = torch.reshape(torch.Tensor(Y_train), (len(Y_train), 1))[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        y_hat = net(x_batch)\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-517-043570e1b9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0me_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-513-90af165482c6>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, opt, criterion, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbeg_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeg_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeg_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeg_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeg_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "e_losses = []\n",
    "num_epochs = 20\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(net, opt, criterion)\n",
    "    clear_output(True)\n",
    "    plt.plot(e_losses,label='loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
